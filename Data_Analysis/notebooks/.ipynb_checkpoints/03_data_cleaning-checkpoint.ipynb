{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 \u2014 Data Cleaning\n**Data Analysis Portfolio**\n\nTopics: missing values, duplicates, invalid values, outlier capping, type fixing, string standardization"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(42)\nprint(\"Ready.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Create Dirty Dataset"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "n = 200\ndf_raw = pd.DataFrame({\n    'emp_id':     list(range(1001,1001+n)) + [1010,1025,1040],\n    'name':       ['Emp_'+str(i) for i in range(n)] + ['Emp_9','Emp_24','Emp_39'],\n    'age':        list(np.random.randint(22,60,n)) + [22,35,45],\n    'department': list(np.random.choice(['IT','HR','Finance','IT ','hr','FINANCE'], n))\n                  + ['IT','HR','Finance'],\n    'salary':     list(np.random.normal(55000,15000,n).round(0)) + [55000,48000,62000],\n    'experience': list(np.random.randint(0,35,n)) + [5,10,15],\n    'gender':     list(np.random.choice(['Male','Female','M','F','male','FEMALE',None], n))\n                  + ['Male','Female','Male'],\n    'rating':     list(np.random.choice([1,2,3,4,5,None,999,-1], n)) + [3,4,5],\n})\nfor col in ['salary','age','experience']:\n    mask = np.random.choice([True,False], len(df_raw), p=[0.08,0.92])\n    df_raw.loc[mask, col] = np.nan\n\ndf_raw.loc[10,'salary']     = 950000   # extreme outlier\ndf_raw.loc[25,'salary']     = -5000    # invalid negative\ndf_raw.loc[50,'age']        = 135      # impossible\ndf_raw.loc[75,'experience'] = 99       # impossible\n\nprint(\"Raw shape:\", df_raw.shape)\nprint(df_raw.head(5))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Audit \u2014 Understand the Mess"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "missing = df_raw.isnull().sum()\npct     = (missing / len(df_raw) * 100).round(1)\naudit   = pd.DataFrame({'count': missing, '%': pct})\nprint(\"Missing Values:\")\nprint(audit[audit['count']>0])\nprint()\nprint(\"Duplicates:\", df_raw.duplicated(subset='emp_id').sum())\nprint()\nfor col in ['department','gender']:\n    print(f\"{col} unique: {df_raw[col].unique()}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Step-by-Step Cleaning"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "df = df_raw.copy()\n\n# STEP 1 \u2014 Remove duplicates\nbefore = len(df)\ndf = df.drop_duplicates(subset='emp_id', keep='first')\nprint(f\"Step 1 \u2014 Removed {before-len(df)} duplicates | shape: {df.shape}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# STEP 2 \u2014 Standardize categories\ndf['department'] = df['department'].str.strip().str.title().replace({'It':'IT','Hr':'HR'})\ngender_map = {'M':'Male','F':'Female','male':'Male','female':'Female','FEMALE':'Female'}\ndf['gender'] = df['gender'].str.strip().replace(gender_map)\ndf['gender'] = df['gender'].where(df['gender'].isin(['Male','Female']), np.nan)\nprint(\"Step 2 \u2014 Departments:\", df['department'].unique())\nprint(\"         Genders:    \", df['gender'].unique())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# STEP 3 \u2014 Fix invalid values\ndf.loc[df['age']>80,       'age']        = np.nan\ndf.loc[df['age']<18,       'age']        = np.nan\ndf.loc[df['salary']<0,     'salary']     = np.nan\ndf.loc[df['experience']>45,'experience'] = np.nan\ndf.loc[~df['rating'].isin([1,2,3,4,5]), 'rating'] = np.nan\n\nQ1 = df['salary'].quantile(0.25)\nQ3 = df['salary'].quantile(0.75)\ncap = Q3 + 3*(Q3-Q1)\ndf.loc[df['salary']>cap, 'salary'] = cap\nprint(f\"Step 3 \u2014 Salary capped at {cap:,.0f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# STEP 4 \u2014 Fill missing values\nfor col in ['age','experience']:\n    df[col] = df[col].fillna(df[col].median())\ndf['salary']  = df.groupby('department')['salary'].transform(lambda x: x.fillna(x.median()))\ndf['gender']  = df['gender'].fillna(df['gender'].mode()[0])\ndf['rating']  = df['rating'].fillna(df['rating'].mode()[0])\nprint(\"Step 4 \u2014 Missing values remaining:\", df.isnull().sum().sum())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# STEP 5 \u2014 Fix types\ndf['age']        = df['age'].astype(int)\ndf['experience'] = df['experience'].astype(int)\ndf['rating']     = df['rating'].astype(int)\ndf['salary']     = df['salary'].round(2)\ndf['gender_code']= df['gender'].map({'Male':0,'Female':1})\nprint(\"Step 5 \u2014 dtypes:\\n\", df.dtypes)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Before vs After"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(\"BEFORE | AFTER\")\nprint(f\"Shape:      {df_raw.shape}  |  {df.shape}\")\nprint(f\"Duplicates: {df_raw.duplicated(subset='emp_id').sum()} | {df.duplicated(subset='emp_id').sum()}\")\nprint(f\"Missing:    {df_raw.isnull().sum().sum()} | {df.isnull().sum().sum()}\")\nprint(f\"Salary max: {df_raw['salary'].max():,.0f} | {df['salary'].max():,.0f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Visualize Cleaned Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\nfig.suptitle('Cleaned Dataset Overview', fontsize=13, fontweight='bold')\n\naxes[0,0].hist(df['salary'], bins=25, color='steelblue', edgecolor='white')\naxes[0,0].set_title('Salary Distribution')\n\ndept = df['department'].value_counts()\naxes[0,1].bar(dept.index, dept.values, color='coral', edgecolor='white')\naxes[0,1].set_title('Department Counts')\n\naxes[1,0].hist(df['age'], bins=20, color='mediumseagreen', edgecolor='white')\naxes[1,0].set_title('Age Distribution')\n\nrating = df['rating'].value_counts().sort_index()\naxes[1,1].bar(rating.index, rating.values, color='mediumpurple', edgecolor='white')\naxes[1,1].set_title('Rating Distribution')\n\nplt.tight_layout()\nplt.savefig('/home/claude/data_analysis_portfolio/notebooks/03_cleaning_plot.png', dpi=100)\nplt.show()\nprint(\"Plot saved.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## \u2705 Cleaning Checklist\n| Issue | Fix |\n|-------|-----|\n| Duplicates | `drop_duplicates()` |\n| Inconsistent strings | `.str.strip().str.title()` + `replace()` |\n| Invalid values | Domain rules + `np.nan` |\n| Outliers | IQR capping |\n| Missing numeric | Median / group median |\n| Missing categorical | Mode |\n| Wrong dtypes | `.astype()` |"
  }
 ]
}