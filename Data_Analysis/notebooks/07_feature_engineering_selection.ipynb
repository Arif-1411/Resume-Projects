{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1d4f3e",
   "metadata": {},
   "source": [
    "# 07 — Feature Engineering & Selection\n",
    "**Data Analysis Portfolio**\n",
    "\n",
    "**Engineering:** encoding, scaling, polynomial, date features, interactions, transforms\n",
    "**Selection:** variance threshold, correlation, SelectKBest, RFE, Random Forest importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(42)\n",
    "print(\"All libraries loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6a086",
   "metadata": {},
   "source": [
    "## 1. Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "df = pd.DataFrame({\n",
    "    'age':          np.random.randint(22,60,n),\n",
    "    'salary':       np.random.lognormal(10.8,0.4,n).round(0).clip(25000,200000),\n",
    "    'experience':   np.random.randint(0,35,n),\n",
    "    'num_projects': np.random.randint(1,20,n),\n",
    "    'department':   np.random.choice(['IT','HR','Finance','Marketing'],n),\n",
    "    'education':    np.random.choice([\"Bachelor's\",\"Master's\",\"PhD\"],n),\n",
    "    'gender':       np.random.choice(['Male','Female'],n),\n",
    "    'join_date':    pd.date_range('2015-01-01',periods=n,freq='3D'),\n",
    "    'noise_1':      np.random.randn(n),\n",
    "    'noise_2':      np.random.randn(n),\n",
    "    'constant_col': 1,\n",
    "})\n",
    "log_odds = 0.03*df['age'] + 0.00001*df['salary'] + 0.05*df['experience'] + 0.1*df['num_projects'] - 3\n",
    "df['promoted'] = (np.random.rand(n) < 1/(1+np.exp(-log_odds))).astype(int)\n",
    "print(\"Shape:\", df.shape, \"| Promoted%:\", round(df['promoted'].mean()*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867367f",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9db636",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = df.copy()\n",
    "# Numeric transforms\n",
    "fe['salary_log']         = np.log1p(fe['salary'])\n",
    "fe['experience_squared'] = fe['experience'] ** 2\n",
    "\n",
    "# Interaction features\n",
    "fe['exp_per_age']         = (fe['experience'] / fe['age']).round(4)\n",
    "fe['salary_per_project']  = (fe['salary'] / fe['num_projects']).round(2)\n",
    "fe['productivity']        = (fe['num_projects'] * fe['salary'] / 1e6).round(4)\n",
    "\n",
    "# Binning\n",
    "fe['age_group']   = pd.cut(fe['age'],  bins=[18,30,40,50,65], labels=['Junior','Mid','Senior','Expert'])\n",
    "fe['salary_tier'] = pd.qcut(fe['salary'], q=4, labels=['Q1','Q2','Q3','Q4'])\n",
    "\n",
    "# Date features\n",
    "fe['join_year']        = fe['join_date'].dt.year\n",
    "fe['join_month']       = fe['join_date'].dt.month\n",
    "fe['join_quarter']     = fe['join_date'].dt.quarter\n",
    "fe['tenure_days']      = (pd.Timestamp('2024-01-01') - fe['join_date']).dt.days\n",
    "fe['is_long_tenure']   = (fe['tenure_days'] > 1000).astype(int)\n",
    "\n",
    "print(f\"Features: {df.shape[1]} → {fe.shape[1]}  (+{fe.shape[1]-df.shape[1]} new)\")\n",
    "print(fe[['salary_log','exp_per_age','tenure_days','productivity']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58954d58",
   "metadata": {},
   "source": [
    "## 3. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2219e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = fe.copy()\n",
    "\n",
    "# Label encode — binary\n",
    "le = LabelEncoder()\n",
    "enc['gender_label']      = le.fit_transform(enc['gender'])\n",
    "\n",
    "# Ordinal encode — ordered categories\n",
    "enc['education_ordinal'] = enc['education'].map({\"Bachelor's\":0,\"Master's\":1,\"PhD\":2})\n",
    "\n",
    "# One-Hot encode — nominal\n",
    "dept_ohe = pd.get_dummies(enc['department'], prefix='dept', drop_first=True)\n",
    "enc = pd.concat([enc, dept_ohe], axis=1)\n",
    "\n",
    "# Drop originals\n",
    "enc = enc.drop(columns=['gender','department','education','join_date','age_group','salary_tier',\n",
    "                          'noise_1','noise_2','constant_col'])\n",
    "\n",
    "print(\"Shape after encoding:\", enc.shape)\n",
    "print(\"OHE columns:\", [c for c in enc.columns if c.startswith('dept')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b252e",
   "metadata": {},
   "source": [
    "## 4. Scaling Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['age','salary','experience','num_projects','tenure_days']\n",
    "X_s = enc[scale_cols].dropna()\n",
    "\n",
    "fig, axes = plt.subplots(len(scale_cols), 4, figsize=(16, 12))\n",
    "fig.suptitle('Scaling Comparison', fontsize=13, fontweight='bold')\n",
    "\n",
    "scalers = [('Original', None), ('MinMax', MinMaxScaler()), ('Standard', StandardScaler()), ('Robust', RobustScaler())]\n",
    "for j, col in enumerate(scale_cols):\n",
    "    for k, (name, scaler) in enumerate(scalers):\n",
    "        data = X_s[[col]]\n",
    "        vals = scaler.fit_transform(data).flatten() if scaler else data[col].values\n",
    "        axes[j,k].hist(vals, bins=20, edgecolor='white',\n",
    "                       color=['salmon','steelblue','mediumseagreen','mediumpurple'][k])\n",
    "        axes[j,k].set_ylabel(col if k==0 else '', fontsize=8)\n",
    "        if j==0: axes[j,k].set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/data_analysis_portfolio/notebooks/07_scaling.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc66d35",
   "metadata": {},
   "source": [
    "## 5. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22488c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = enc.drop(columns=['promoted']).select_dtypes(include=[np.number]).fillna(0)\n",
    "y = enc['promoted']\n",
    "print(\"Features:\", X.shape[1])\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3850dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1 — Variance Threshold\n",
    "vt = VarianceThreshold(threshold=0.01)\n",
    "vt.fit(X)\n",
    "dropped = X.columns[~vt.get_support()].tolist()\n",
    "print(f\"Variance Threshold — dropped {len(dropped)}: {dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43de40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 2 — Correlation Filter\n",
    "corr  = X.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "hi    = [c for c in upper.columns if any(upper[c] > 0.90)]\n",
    "print(f\"High correlation (>0.90): {hi}\")\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(corr, cmap='coolwarm', linewidths=0.3, xticklabels=True, yticklabels=True)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.xticks(fontsize=7, rotation=45, ha='right')\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/data_analysis_portfolio/notebooks/07_corr.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a5c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 3 — SelectKBest\n",
    "skb      = SelectKBest(score_func=f_classif, k=8)\n",
    "skb.fit(X, y)\n",
    "selected = X.columns[skb.get_support()].tolist()\n",
    "scores   = pd.Series(skb.scores_, index=X.columns).sort_values(ascending=False)\n",
    "print(\"SelectKBest top 8:\", selected)\n",
    "print(scores.head(10).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dedb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 4 — Random Forest Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "imp = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "imp.head(12).plot(kind='bar', color='steelblue', edgecolor='white')\n",
    "plt.title('Random Forest — Feature Importance', fontsize=13, fontweight='bold')\n",
    "plt.xticks(rotation=35, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/data_analysis_portfolio/notebooks/07_importance.png', dpi=100)\n",
    "plt.show()\n",
    "print(\"Top 5:\", imp.head(5).round(4).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 5 — RFE\n",
    "rfe = RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=8)\n",
    "rfe.fit(X, y)\n",
    "rfe_feats = X.columns[rfe.support_].tolist()\n",
    "print(\"RFE selected:\", rfe_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c955c5f",
   "metadata": {},
   "source": [
    "## 6. Compare All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_top8 = imp.head(8).index.tolist()\n",
    "all3    = set(selected) & set(rf_top8) & set(rfe_feats)\n",
    "print(\"=\"*55)\n",
    "print(\"FEATURE SELECTION SUMMARY\")\n",
    "print(\"=\"*55)\n",
    "print(f\"Total features:        {X.shape[1]}\")\n",
    "print(f\"SelectKBest:           {selected}\")\n",
    "print(f\"RF Importance (top 8): {rf_top8}\")\n",
    "print(f\"RFE:                   {rfe_feats}\")\n",
    "print(f\"\\nConsensus features (all 3 methods): {sorted(all3)}\")\n",
    "print(\"\\n→ These are your MOST RELIABLE features for ML models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4ff13",
   "metadata": {},
   "source": [
    "---\n",
    "## ✅ Full Summary\n",
    "| Category | Technique | Tool |\n",
    "|----------|-----------|------|\n",
    "| **Engineering** | Log/sqrt | `np.log1p()` |\n",
    "| | Interaction | `col1/col2`, `col1*col2` |\n",
    "| | Binning | `pd.cut()`, `pd.qcut()` |\n",
    "| | Date features | `.dt.year`, tenure |\n",
    "| **Encoding** | Binary | `LabelEncoder` |\n",
    "| | Ordinal | manual `map()` |\n",
    "| | Nominal | `pd.get_dummies()` |\n",
    "| **Scaling** | Normalize | `MinMaxScaler` |\n",
    "| | Standardize | `StandardScaler` |\n",
    "| | Robust | `RobustScaler` |\n",
    "| **Selection** | Variance | `VarianceThreshold` |\n",
    "| | Correlation | manual filter |\n",
    "| | Univariate | `SelectKBest` |\n",
    "| | Wrapper | `RFE` |\n",
    "| | Embedded | `RandomForestClassifier` |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
